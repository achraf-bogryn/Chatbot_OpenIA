# ğŸ’¬ Friendly Q&A Chatbot (Ollama + OpenAI)

## Introduction
Welcome to the **Friendly Q&A Chatbot**, a versatile AI-powered chatbot built using **LangChain**, **Ollama**, and **OpenAI**.  
This application allows users to interact with AI models either **locally** through Ollama or **via OpenAI API**, providing a **friendly, conversational experience** with customizable settings for temperature, response length, and model selection.  

**Preview of the Application:**

- *When using OpenAI models:*  
  ![OpenAI Chatbot](images/openAi.PNG)  
  *Screenshot showing the chatbot running with OpenAI (e.g., GPT-4o).*  

- *When using Ollama models:*  
  ![Ollama Chatbot](images/ollama.PNG)  
  *Screenshot showing the chatbot running with Ollama (e.g., Llama2 or Gemma).*  

---

## Problem Statement
Many users need a conversational assistant to answer questions, summarize information, or provide guidance. Traditional cloud-based AI chatbots may expose sensitive data or require constant internet access.  

This project addresses these challenges by providing:

- **Local AI inference** via Ollama for privacy and offline usage.
- **Cloud AI access** via OpenAI for high-quality responses.
- **Interactive and friendly chat interface**.

**Illustration of the problem:**  
![Problem Illustration](images/chatbot-best-practices.webp)  
*Example showing how the chatbot helps users get answers safely and efficiently.*

---

## Features
- Chat with **OpenAI models** (`gpt-4o`, `gpt-4-turbo`, `gpt-4`, `gpt-3.5-turbo`)  
- Chat with **local Ollama models** (`llama2:latest`, `gemma:2b`)  
- Friendly, chat-like interface with **conversation history**  
- Adjustable **temperature** and **response length**  
- **Combined interface** to switch between OpenAI and Ollama  
- Easy integration of **new AI models**  

---

## Configuration Parameters
The chatbot includes customizable parameters to control how responses are generated:

### ğŸ”¥ Temperature
- **What it does:** Controls how *creative or deterministic* the responses are.  
- **Range:** `0.0` â†’ `2.0`  
  - `0.0` = very focused, repetitive, deterministic answers.  
  - `1.0` = balanced creativity.  
  - `2.0` = highly random and imaginative responses.  
- **Example:**  
  - *Temperature 0.2:* â€œThe capital of France is Paris.â€  
  - *Temperature 1.2:* â€œParis is the capital, but you might also love its culture, food, and art!â€  

### ğŸ“ Max Tokens
- **What it does:** Defines the **maximum length of the modelâ€™s response** (in tokens, not characters).  
- **Range:** Depends on the model (e.g., GPT-4o supports up to ~128k tokens).  
- **Why it matters:**  
  - Higher values allow **longer, more detailed answers**.  
  - Lower values enforce **short, concise answers**.  
- **Example:**  
  - *max_tokens = 50* â†’ â€œParis is the capital of France.â€  
  - *max_tokens = 500* â†’ Detailed answer with history, culture, and extra context about Paris.  

---

## Technologies Used
- **Python 3.10+**  
- **Streamlit** â€“ interactive web interface  
- **LangChain** â€“ orchestrating AI prompts and chains  
- **Ollama** â€“ local AI inference  
- **OpenAI API** â€“ cloud AI inference  
- **Markdown & Session State** â€“ for chat formatting  

---

## Project Structure

``` bash
ğŸ“‚ chatbot-project
 â”œâ”€â”€ ğŸ“„ Chat.py                  # Combined chatbot (OpenAI + Ollama interface)
 â”œâ”€â”€ ğŸ“„ requirements.txt         # Python dependencies
 â”œâ”€â”€ ğŸ“„ README.md                # Project documentation
 â”œâ”€â”€ ğŸ“„ .gitignore               # Ignored files (env, cache, etc.)
 â”‚
 â”œâ”€â”€ ğŸ“‚ images/                  # Screenshots & illustrations
 â”‚    â”œâ”€â”€ openai_chatbot.png         # Preview of chatbot with OpenAI
 â”‚    â”œâ”€â”€ ollama_chatbot.png         # Preview of chatbot with Ollama
 â”‚    â””â”€â”€ chatbot-best-practices.webp # Problem illustration
 â”‚
 â”œâ”€â”€ ğŸ“‚ OpenAI_chatbot/          # OpenAI-only chatbot app
 â”‚    â””â”€â”€ app.py                     # Streamlit app for OpenAI models
 â”‚
 â””â”€â”€ ğŸ“‚ Ollama_chatbot/          # Ollama-only chatbot app
      â””â”€â”€ main.py                    # Streamlit app for Ollama models
```
